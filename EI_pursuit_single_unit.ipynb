{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from own EIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from extract_data_snippets import extract_snippets\n",
    "from verify_cluster import compute_ei\n",
    "from run_template_scoring_gpu import run_template_scoring_gpu\n",
    "from suppress_close_peaks import suppress_close_peaks\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# --- Parameters ---\n",
    "sampling_rate = 20000\n",
    "dat_path = '/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat'\n",
    "h5_in_path = '/Volumes/Lab/Users/alexth/axolotl/201703151_kilosort_data001_spike_times.h5'\n",
    "h5_ei_path = '/Volumes/Lab/Users/alexth/axolotl/ks_eis_subset.h5'\n",
    "\n",
    "unit_id_to_process = 8  # KS unit ID\n",
    "\n",
    "# --- Load spike times and KS template ---\n",
    "with h5py.File(h5_in_path, 'r') as f:\n",
    "    spikes_sec = np.array(f[f'/spikes/unit_{unit_id_to_process}'][:]).flatten()\n",
    "    spike_times = np.round(spikes_sec * sampling_rate).astype(np.int32)\n",
    "\n",
    "# --- Compute EI template ---\n",
    "spike_subset = spike_times[:1000]  # or fewer if needed\n",
    "snips = extract_snippets(dat_path, spike_subset, window=(-20, 60))\n",
    "ei_template = compute_ei(snips)\n",
    "\n",
    "# --- Channel selection and normalization ---\n",
    "ei_peak2peak = ei_template.max(axis=1) - ei_template.min(axis=1)\n",
    "selected_by_ei = np.where(ei_peak2peak > 15)[0]\n",
    "if len(selected_by_ei) > 80:\n",
    "    selected_by_ei = np.argsort(ei_peak2peak)[-80:]\n",
    "elif len(selected_by_ei) < 30:\n",
    "    selected_by_ei = np.argsort(ei_peak2peak)[-30:]\n",
    "\n",
    "ei_masks = np.zeros_like(ei_template)\n",
    "ei_masks[selected_by_ei, :] = 1\n",
    "ei_norms = np.linalg.norm(ei_template * ei_masks, axis=1)\n",
    "\n",
    "ei_masks_subset = ei_masks[selected_by_ei, :]\n",
    "ei_norms_subset = ei_norms[selected_by_ei]\n",
    "\n",
    "print(\"now running template scan\")\n",
    "# --- Template scoring ---\n",
    "mean_score, max_score, valid_score = run_template_scoring_gpu(\n",
    "    dat_path=dat_path,\n",
    "    ei_template=ei_template[selected_by_ei, :],\n",
    "    ei_masks=ei_masks_subset,\n",
    "    ei_norms=ei_norms_subset,\n",
    "    selected_channels=selected_by_ei,\n",
    "    start_sample=0,\n",
    "    GPU_samples=36_000_000,  # or however long the recording is\n",
    "    dtype='int16'\n",
    ")\n",
    "\n",
    "# --- Detect spike times from template scoring ---\n",
    "score_threshold = max(np.mean(np.sum((ei_template[selected_by_ei, :] * ei_masks[selected_by_ei, :]) ** 2, axis=1)) / 2, 20000)\n",
    "\n",
    "is_peak = argrelextrema(mean_score, np.greater_equal, order=1)[0]\n",
    "#valid_inds = is_peak[(mean_score[is_peak] > score_threshold) & (valid_score[is_peak] > 3)]\n",
    "peak_mask = (mean_score[is_peak] > score_threshold) & (valid_score[is_peak] > 3)\n",
    "candidates = is_peak[peak_mask]\n",
    "refractory_samples = int(0.001 * 20000)\n",
    "valid_inds = suppress_close_peaks(candidates, mean_score, refractory_samples)\n",
    "\n",
    "final_spike_times = valid_inds + 19  # offset from template alignment\n",
    "\n",
    "print(\"Final spikes: \", len(final_spike_times))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### from data000 EIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_multi_gpu_ei_scan import run_multi_gpu_ei_scan\n",
    "\n",
    "\n",
    "#mean_score, max_score, valid_score, selected_channels, ei_template = run_multi_gpu_ei_scan(\n",
    "#    ei_mat_path='/Volumes/Lab/Users/alexth/axolotl/ei_template_data000_cell388.mat',\n",
    "#    dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat',\n",
    "#    total_samples=36_000_000,   # fill in with length of your recording in samples\n",
    "#    save_prefix = '/Volumes/Lab/Users/alexth/axolotl/201703151_data000_tmp'\n",
    "#)\n",
    "\n",
    "mean_score, max_score, valid_score, selected_channels, ei_template = run_multi_gpu_ei_scan(\n",
    "    ei_mat_path='/Volumes/Lab/Users/alexth/axolotl/ei_template_data001_cell231.mat',\n",
    "    dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001_sub.dat',\n",
    "    total_samples=36_000_000,   # fill in with length of your recording in samples\n",
    "    save_prefix = '/Volumes/Lab/Users/alexth/axolotl/201703151_data000_tmp'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "import numpy as np\n",
    "from suppress_close_peaks import suppress_close_peaks\n",
    "\n",
    "mask = np.zeros_like(ei_template)\n",
    "mask[selected_channels, :] = 1\n",
    "masked_template = ei_template[selected_channels, :] * mask[selected_channels, :]\n",
    "dot_scores = np.sum(masked_template ** 2, axis=1)\n",
    "score_threshold = max(np.mean(dot_scores) / 2, 1000)\n",
    "peaks = argrelextrema(mean_score, np.greater_equal, order=1)[0]\n",
    "#valid_inds = is_peak[(mean_score[is_peak] > score_threshold) & (valid_score[is_peak] > 3)]\n",
    "peak_mask = (mean_score[peaks] > score_threshold) & (valid_score[peaks] > 3)\n",
    "candidates = peaks[peak_mask]\n",
    "refractory_samples = int(0.002 * 20000)\n",
    "valid_inds = suppress_close_peaks(candidates, mean_score, refractory_samples)\n",
    "final_spike_times = valid_inds + 19\n",
    "print(len(final_spike_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verify_cluster\n",
    "import importlib\n",
    "importlib.reload(verify_cluster)\n",
    "print(\"now running cluster verification\")\n",
    "\n",
    "dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat'\n",
    "\n",
    "# --- Run recursive cluster verification ---\n",
    "params = {\n",
    "    'window': (-20, 60),\n",
    "    'min_spikes': 100,\n",
    "    'ei_sim_threshold': 0.8,\n",
    "    'k_start': 4,\n",
    "    'k_refine': 2\n",
    "}\n",
    "\n",
    "clusters = verify_cluster.verify_cluster(spike_times=final_spike_times, dat_path=dat_path, params=params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_clusters\n",
    "import importlib\n",
    "importlib.reload(analyze_clusters)\n",
    "\n",
    "\n",
    "analyze_clusters.analyze_clusters(clusters,\n",
    "                 spike_times=final_spike_times,\n",
    "                 sampling_rate=20000,\n",
    "                 dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001_sub.dat',\n",
    "                 h5_path='/Volumes/Lab/Users/alexth/axolotl/201703151_kilosort_data001_spike_times.h5',\n",
    "                 triggers_mat_path='/Volumes/Lab/Users/alexth/axolotl/trigger_in_samples_201703151.mat',\n",
    "                 cluster_ids=[0],\n",
    "                 lut=None,\n",
    "                 sta_depth=30,\n",
    "                 sta_offset=0,\n",
    "                 sta_chunk_size=1000,\n",
    "                 sta_refresh=2,\n",
    "                 ei_scale=3,\n",
    "                 ei_cutoff=0.08, \n",
    "                 template_ei=ei_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verify final cluster for overmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verify_cluster import verify_cluster\n",
    "\n",
    "spike_times_refined = final_spike_times[clusters[0]['inds']]\n",
    "\n",
    "params = {\n",
    "    'window': (-20, 60),\n",
    "    'min_spikes': 100,\n",
    "    'ei_sim_threshold': 0.95,\n",
    "    'k_start': 8,\n",
    "    'k_refine': 2\n",
    "}\n",
    "\n",
    "clusters_refined = verify_cluster(\n",
    "    spike_times=spike_times_refined,\n",
    "    dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat',\n",
    "    params=params\n",
    ")\n",
    "\n",
    "print(f\"Returned {len(clusters_refined)} clean subclusters\")\n",
    "for i, cl in enumerate(clusters_refined):\n",
    "    print(f\"  Cluster {i}: {len(cl['inds'])} spikes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_clusters\n",
    "import importlib\n",
    "importlib.reload(analyze_clusters)\n",
    "\n",
    "\n",
    "analyze_clusters.analyze_clusters(clusters_refined,\n",
    "                 spike_times=spike_times_refined,\n",
    "                 sampling_rate=20000,\n",
    "                 dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat',\n",
    "                 h5_path='/Volumes/Lab/Users/alexth/axolotl/201703151_kilosort_data001_spike_times.h5',\n",
    "                 triggers_mat_path='/Volumes/Lab/Users/alexth/axolotl/trigger_in_samples_201703151.mat',\n",
    "                 cluster_ids=None, #list(range(7, 13))\n",
    "                 lut=None,\n",
    "                 sta_depth=30,\n",
    "                 sta_offset=0,\n",
    "                 sta_chunk_size=1000,\n",
    "                 sta_refresh=2,\n",
    "                 ei_scale=3,\n",
    "                 ei_cutoff=0.08, \n",
    "                 isi_max_ms=100,\n",
    "                 template_ei=ei_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plot_ei_waveforms\n",
    "import importlib\n",
    "importlib.reload(plot_ei_waveforms)\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "h5_path = '/Volumes/Lab/Users/alexth/axolotl/201703151_kilosort_data001_spike_times.h5'\n",
    "\n",
    "with h5py.File(h5_path, 'r') as f:\n",
    "    # Load electrode positions\n",
    "    ei_positions = f['/ei_positions'][:].T  # shape becomes [512 x 2]\n",
    "\n",
    "\n",
    "#ei = clusters[1]['ei']\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "#plot_ei_waveforms.plot_ei_waveforms([clusters_refined[3]['ei'][:, 0:61], clusters_refined[2]['ei'][:, 0:61], ei_template], ei_positions,\n",
    "#                  colors=[ 'red', 'blue', 'black'], scale=70, box_height=1.0, box_width=50)\n",
    "\n",
    "#plot_ei_waveforms.plot_ei_waveforms([clusters_refined[3]['ei'][:, 0:61], clusters_refined[2]['ei'][:, 0:61],clusters_refined[0]['ei'][:, 0:61], ei_template], ei_positions,\n",
    "#                  colors=[ 'red', 'blue', 'green','black'], scale=70, box_height=1.0, box_width=50)\n",
    "\n",
    "plot_ei_waveforms.plot_ei_waveforms([clusters_refined[0]['ei'][:, 0:61], ei_template], ei_positions,\n",
    "                  colors=[ 'red', 'blue', 'green','black'], scale=70, box_height=1.0, box_width=50)\n",
    "\n",
    "#plot_ei_waveforms.plot_ei_waveforms(ei, ei_positions, scale=70.0, box_height=1.0, box_width=50.0, color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_smoothed_firing_rates import plot_smoothed_firing_rates\n",
    "\n",
    "spike_times_1 = spike_times_refined[clusters_refined[0]['inds']] / sampling_rate\n",
    "spike_times_2 = spike_times_refined[clusters_refined[2]['inds']] / sampling_rate\n",
    "\n",
    "#plot_smoothed_firing_rates([spike_times_1, spike_times_2], labels=[\"Cluster 0\", \"Cluster 2\"], sigma_ms=250, dt_ms=1, total_duration_s=100)\n",
    "plot_smoothed_firing_rates([spike_times_1, spike_times_2], labels=[\"Cluster 0\", \"Cluster 2\"], sigma_ms=2500, dt_ms=1000, total_duration_s=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_and_plot_xcorr import compute_and_plot_xcorr\n",
    "\n",
    "sampling_rate = 20000\n",
    "# Get spike times (in seconds) from two clusters\n",
    "spike_times_1 = spike_times_refined[clusters_refined[0]['inds']] / sampling_rate\n",
    "spike_times_2 = spike_times_refined[clusters_refined[1]['inds']] / sampling_rate\n",
    "\n",
    "compute_and_plot_xcorr(spike_times_1, spike_times_2, bin_size_ms=0.5, max_lag_ms=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from verify_cluster import verify_cluster\n",
    "\n",
    "spike_times_refined1 = spike_times_refined[clusters_refined[0]['inds']]\n",
    "\n",
    "params = {\n",
    "    'window': (-20, 60),\n",
    "    'min_spikes': 100,\n",
    "    'ei_sim_threshold': 0.95,\n",
    "    'k_start': 8,\n",
    "    'k_refine': 2\n",
    "}\n",
    "\n",
    "clusters_refined1 = verify_cluster(\n",
    "    spike_times=spike_times_refined1,\n",
    "    dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat',\n",
    "    params=params\n",
    ")\n",
    "\n",
    "print(f\"Returned {len(clusters_refined1)} clean subclusters\")\n",
    "for i, cl in enumerate(clusters_refined1):\n",
    "    print(f\"  Cluster {i}: {len(cl['inds'])} spikes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_clusters\n",
    "import importlib\n",
    "importlib.reload(analyze_clusters)\n",
    "\n",
    "\n",
    "analyze_clusters.analyze_clusters(clusters_refined1,\n",
    "                 spike_times=spike_times_refined1,\n",
    "                 sampling_rate=20000,\n",
    "                 dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat',\n",
    "                 h5_path='/Volumes/Lab/Users/alexth/axolotl/201703151_kilosort_data001_spike_times.h5',\n",
    "                 triggers_mat_path='/Volumes/Lab/Users/alexth/axolotl/trigger_in_samples_201703151.mat',\n",
    "                 cluster_ids=None, #list(range(7, 13))\n",
    "                 lut=None,\n",
    "                 sta_depth=30,\n",
    "                 sta_offset=0,\n",
    "                 sta_chunk_size=1000,\n",
    "                 sta_refresh=2,\n",
    "                 ei_scale=3,\n",
    "                 ei_cutoff=0.08, \n",
    "                 template_ei=ei_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_spikes_by_burst import split_spikes_by_burst\n",
    "import analyze_clusters\n",
    "import importlib\n",
    "importlib.reload(analyze_clusters)\n",
    "\n",
    "#spike_times_refined = final_spike_times[clusters[10]['inds']]\n",
    "\n",
    "clusters1 = split_spikes_by_burst(spike_times_refined, sampling_rate=20000)\n",
    "\n",
    "\n",
    "analyze_clusters.analyze_clusters(clusters1,\n",
    "                 spike_times=spike_times_refined,\n",
    "                 sampling_rate=20000,\n",
    "                 dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat',\n",
    "                 h5_path='/Volumes/Lab/Users/alexth/axolotl/201703151_kilosort_data001_spike_times.h5',\n",
    "                 triggers_mat_path='/Volumes/Lab/Users/alexth/axolotl/trigger_in_samples_201703151.mat',\n",
    "                 cluster_ids=None, #list(range(7, 13))\n",
    "                 lut=None,\n",
    "                 sta_depth=30,\n",
    "                 sta_offset=0,\n",
    "                 sta_chunk_size=1000,\n",
    "                 sta_refresh=2,\n",
    "                 ei_scale=3,\n",
    "                 ei_cutoff=0.08, \n",
    "                 template_ei=ei_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge [0,1,2,6] into one\n",
    "inds_merge_1 = np.concatenate([clusters[i]['inds'] for i in [0]])\n",
    "\n",
    "# Merge [3,4] into another\n",
    "#inds_merge_2 = np.concatenate([clusters[i]['inds'] for i in [2,3]])\n",
    "\n",
    "# Keep cluster[5] as-is\n",
    "inds_keep = clusters[0]['inds']\n",
    "\n",
    "# Final merged list of clusters (order doesn't matter here)\n",
    "merged_clusters = [\n",
    " #   {'inds': inds_merge_1},\n",
    " #   {'inds': inds_merge_2},\n",
    "    {'inds': inds_keep}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analyze_clusters\n",
    "import importlib\n",
    "importlib.reload(analyze_clusters)\n",
    "\n",
    "\n",
    "analyze_clusters.analyze_clusters(merged_clusters,\n",
    "                 spike_times=final_spike_times,\n",
    "                 sampling_rate=20000,\n",
    "                 dat_path='/Volumes/Lab/Users/alexth/axolotl/201703151_data001.dat',\n",
    "                 h5_path='/Volumes/Lab/Users/alexth/axolotl/201703151_kilosort_data001_spike_times.h5',\n",
    "                 triggers_mat_path='/Volumes/Lab/Users/alexth/axolotl/trigger_in_samples_201703151.mat',\n",
    "                 cluster_ids=[1],\n",
    "                 lut=None,\n",
    "                 sta_depth=30,\n",
    "                 sta_offset=0,\n",
    "                 sta_chunk_size=1000,\n",
    "                 sta_refresh=2,\n",
    "                 ei_scale=3,\n",
    "                 ei_cutoff=0.08)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoencoder_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
